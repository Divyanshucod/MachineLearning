{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important files import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading data\n",
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check null value present\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the distribution of categories in 'Column1'\n",
    "# sns.countplot(x='Sex', data=df) ## M,F\n",
    "# sns.countplot(x='ChestPainType', data=df) ## ATA, NAP,ASY,TA\n",
    "# sns.countplot(x='RestingECG', data=df) ## Normal, ST,LVH\n",
    "sns.countplot(x='ST_Slope', data=df) ## Normal,ST,LVH\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features engineering and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one-hot encoding\n",
    "updatedDf = pd.get_dummies(df,columns=['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope'])\n",
    "updatedDf = updatedDf.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new dataset which is clean\n",
    "updatedDf.to_csv('heart_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reording the columns\n",
    "\n",
    "# Get the name of the 5th column\n",
    "fifth_column_name = updatedDf.columns[6]\n",
    "\n",
    "# Create a new list of column names with the 5th column at the end\n",
    "new_column_order = updatedDf.columns[:6].tolist() + updatedDf.columns[7:].tolist() + [fifth_column_name]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "updatedDf = updatedDf[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dependent and independent feature split\n",
    "X = updatedDf.iloc[:,:20]\n",
    "Y = updatedDf.iloc[:,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedDf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.30,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## features scalling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regression = LogisticRegression()\n",
    "regression.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print(accuracy_score(Y_test,y_pred))\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and the logistic regression curve\n",
    "plt.scatter(X_train, Y_train)\n",
    "plt.plot(X_test, y_pred, color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Logistic Regression Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertunning and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "penalty = ['l1','l2','elasticnet']\n",
    "solver = ['lbfgs','liblinear','newton-cg','newton-cholesky','saga','sag']\n",
    "c_values = [100,10,1.0,0.1,0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(penalty=penalty,C=c_values,solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stratifiedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "cv = StratifiedGroupKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model,param_grid=params,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(X_train,Y_train)\n",
    "Y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
